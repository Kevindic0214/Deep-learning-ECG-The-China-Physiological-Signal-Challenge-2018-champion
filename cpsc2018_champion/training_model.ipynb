{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG structure type: <class 'numpy.ndarray'>\n",
      "ECG shape: (1, 1)\n",
      "ECG data: [[(array(['Male'], dtype='<U4'), array([[74]], dtype=uint8), array([[ 0.0282288 ,  0.0392288 ,  0.0452288 , ...,  0.2582288 ,\n",
      "           0.2592288 ,  0.2592288 ],\n",
      "         [ 0.00672947,  0.01072947,  0.01472947, ...,  0.24772947,\n",
      "           0.24872947,  0.24972947],\n",
      "         [-0.02149933, -0.02849933, -0.03049933, ..., -0.01049933,\n",
      "          -0.01049933, -0.00949933],\n",
      "         ...,\n",
      "         [-0.11200653, -0.11000653, -0.10800653, ...,  0.19399347,\n",
      "           0.19399347,  0.19499347],\n",
      "         [-0.5959572 , -0.5899572 , -0.5819572 , ...,  0.3070428 ,\n",
      "           0.3070428 ,  0.3070428 ],\n",
      "         [-0.01558507, -0.00658507,  0.00241493, ...,  0.21341493,\n",
      "           0.21441493,  0.21441493]]))                                                                                       ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Replace with your .mat file path\n",
    "mat_file_path = r'D:\\NYCU\\Introduction to Artificial Intelligence\\Final Project\\Project\\TrainingSet1\\A0001.mat'\n",
    "data = loadmat(mat_file_path)\n",
    "\n",
    "# View the detailed structure of the ECG variable\n",
    "ecg_data = data['ECG']\n",
    "print(\"ECG structure type:\", type(ecg_data))\n",
    "print(\"ECG shape:\", ecg_data.shape)\n",
    "print(\"ECG data:\", ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ECG data: 100%|██████████| 2000/2000 [00:30<00:00, 66.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_save_ecg_data(folder_path, save_path):\n",
    "    max_length = 72000  # A uniform length of 72000\n",
    "\n",
    "    for filename in tqdm(sorted(os.listdir(folder_path)), desc=\"Processing ECG data\", mininterval=0.5):\n",
    "        if filename.endswith('.mat'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            mat_data = sio.loadmat(file_path)\n",
    "            \n",
    "            # Extract ECG signal data\n",
    "            ecg_record = mat_data['ECG'][0][0][2]\n",
    "            \n",
    "            # Check if the number of leads is 12\n",
    "            if ecg_record.shape[0] != 12:\n",
    "                print(f\"Warning: {filename} does not contain 12 leads\")\n",
    "                continue\n",
    "\n",
    "            # Zero padding\n",
    "            ecg_record_padded = np.pad(ecg_record, ((0, 0), (0, max_length - ecg_record.shape[1])), 'constant')\n",
    "\n",
    "            # Save each processed file as `.npy` format\n",
    "            save_filename = os.path.join(save_path, f\"{os.path.splitext(filename)[0]}.npy\")\n",
    "            np.save(save_filename, ecg_record_padded)\n",
    "\n",
    "# Replace with your folder path\n",
    "folder_path = r'D:\\NYCU\\Introduction to Artificial Intelligence\\Final Project\\Project\\TrainingSet1'\n",
    "save_path = r'D:\\NYCU\\Introduction to Artificial Intelligence\\Final Project\\Project\\Processed Data'\n",
    "\n",
    "# Ensure the save folder exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "process_and_save_ecg_data(folder_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (12, 72000)\n",
      "Data sample: [[ 2.82288000e-02  3.92288000e-02  4.52288000e-02  4.92288000e-02\n",
      "   5.42288000e-02  5.62288000e-02  5.82288000e-02  6.02288000e-02\n",
      "   6.02288000e-02  6.12288000e-02]\n",
      " [ 6.72946667e-03  1.07294667e-02  1.47294667e-02  1.67294667e-02\n",
      "   1.97294667e-02  2.37294667e-02  2.87294667e-02  3.47294667e-02\n",
      "   4.07294667e-02  4.77294667e-02]\n",
      " [-2.14993333e-02 -2.84993333e-02 -3.04993333e-02 -3.24993333e-02\n",
      "  -3.44993333e-02 -3.24993333e-02 -2.94993333e-02 -2.54993333e-02\n",
      "  -1.94993333e-02 -1.34993333e-02]\n",
      " [-1.74906667e-02 -2.44906667e-02 -2.94906667e-02 -3.24906667e-02\n",
      "  -3.64906667e-02 -3.94906667e-02 -4.24906667e-02 -4.74906667e-02\n",
      "  -5.04906667e-02 -5.44906667e-02]\n",
      " [ 2.43552000e-02  3.33552000e-02  3.83552000e-02  4.13552000e-02\n",
      "   4.43552000e-02  4.43552000e-02  4.43552000e-02  4.23552000e-02\n",
      "   3.93552000e-02  3.63552000e-02]\n",
      " [-6.80013333e-03 -8.80013333e-03 -6.80013333e-03 -6.80013333e-03\n",
      "  -6.80013333e-03 -3.80013333e-03  1.99866667e-04  4.19986667e-03\n",
      "   1.01998667e-02  1.61998667e-02]\n",
      " [-2.90052000e-01 -3.04052000e-01 -3.17052000e-01 -3.29052000e-01\n",
      "  -3.42052000e-01 -3.53052000e-01 -3.64052000e-01 -3.73052000e-01\n",
      "  -3.82052000e-01 -3.90052000e-01]\n",
      " [-2.04020933e-01 -2.12020933e-01 -2.19020933e-01 -2.26020933e-01\n",
      "  -2.33020933e-01 -2.39020933e-01 -2.46020933e-01 -2.51020933e-01\n",
      "  -2.58020933e-01 -2.64020933e-01]\n",
      " [-9.56593333e-02 -9.96593333e-02 -1.04659333e-01 -1.08659333e-01\n",
      "  -1.10659333e-01 -1.12659333e-01 -1.13659333e-01 -1.13659333e-01\n",
      "  -1.13659333e-01 -1.12659333e-01]\n",
      " [-1.12006533e-01 -1.10006533e-01 -1.08006533e-01 -1.05006533e-01\n",
      "  -1.00006533e-01 -9.60065333e-02 -9.00065333e-02 -8.20065333e-02\n",
      "  -7.40065333e-02 -6.50065333e-02]\n",
      " [-5.95957200e-01 -5.89957200e-01 -5.81957200e-01 -5.72957200e-01\n",
      "  -5.60957200e-01 -5.50957200e-01 -5.37957200e-01 -5.25957200e-01\n",
      "  -5.12957200e-01 -4.99957200e-01]\n",
      " [-1.55850667e-02 -6.58506667e-03  2.41493333e-03  1.34149333e-02\n",
      "   2.44149333e-02  3.54149333e-02  4.74149333e-02  6.14149333e-02\n",
      "   7.54149333e-02  8.84149333e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "npy_file_path = r'D:\\NYCU\\Introduction to Artificial Intelligence\\Final Project\\Project\\Processed Data\\A0001.npy'\n",
    "\n",
    "# Load the .npy file\n",
    "data = np.load(npy_file_path)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(\"Data shape:\", data.shape)\n",
    "\n",
    "# View a portion of the data (first 10 data points)\n",
    "print(\"Data sample:\", data[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recording  First_label  Second_label  Third_label\n",
      "0     A0001            5           NaN          NaN\n",
      "1     A0002            1           NaN          NaN\n",
      "2     A0003            2           NaN          NaN\n",
      "3     A0004            2           NaN          NaN\n",
      "4     A0005            7           NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the label CSV\n",
    "reference_path = r'D:\\NYCU\\Introduction to Artificial Intelligence\\Final Project\\Project\\REFERENCE_1.csv'\n",
    "labels_df = pd.read_csv(reference_path)\n",
    "\n",
    "# Check the loaded data\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recording  First_label  Second_label  Third_label\n",
      "0     A0001            5           NaN          NaN\n",
      "1     A0002            1           NaN          NaN\n",
      "2     A0003            2           NaN          NaN\n",
      "3     A0004            2           NaN          NaN\n",
      "4     A0005            7           NaN          NaN\n",
      "Total valid files: 2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the label CSV\n",
    "labels_df = pd.read_csv(reference_path)\n",
    "\n",
    "# Set the folder path\n",
    "folder_path = r'D:\\NYCU\\Introduction to Artificial Intelligence\\Final Project\\Project\\Processed Data'\n",
    "\n",
    "# Optimize file existence check by preloading existing .npy files\n",
    "existing_files = {file_name for file_name in os.listdir(folder_path) if file_name.endswith('.npy')}\n",
    "labels_df = labels_df[labels_df['Recording'].apply(lambda x: f\"{x}.npy\" in existing_files)]\n",
    "\n",
    "# Check the filtered data\n",
    "print(labels_df.head())\n",
    "print(f\"Total valid files: {len(labels_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded labels shape: torch.Size([2000, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假設有 9 個類別\n",
    "num_classes = 9\n",
    "labels = labels_df['First_label'] - 1  # 將標籤從 0 開始\n",
    "y = torch.nn.functional.one_hot(torch.tensor(labels.values), num_classes=num_classes)\n",
    "print(\"One-hot encoded labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 2000/2000 [00:21<00:00, 91.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([2000, 12, 72000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 載入數據並轉換為 PyTorch 張量\n",
    "X = []\n",
    "for recording_name in tqdm(labels_df['Recording'], desc=\"Loading files\", mininterval=0.5):\n",
    "    file_path = os.path.join(folder_path, f\"{recording_name}.npy\")\n",
    "    if os.path.exists(file_path):\n",
    "        X.append(torch.tensor(np.load(file_path).astype(np.float32)))\n",
    "\n",
    "# 將列表中的所有張量堆疊成單一張量\n",
    "X = torch.stack(X)\n",
    "print(\"Data shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([1400, 12, 72000]) torch.Size([1400, 9])\n",
      "Testing data shape: torch.Size([600, 12, 72000]) torch.Size([600, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假設 X 和 y 是 PyTorch 張量\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 將分割出的資料轉換為 PyTorch 張量格式\n",
    "X_train = X_train.clone().detach()\n",
    "X_test = X_test.clone().detach()\n",
    "y_train = y_train.clone().detach()\n",
    "y_test = y_test.clone().detach()\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Package the data into PyTorch Datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Use DataLoader for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.clone().detach().float()\n",
    "y_train = y_train.clone().detach().float()\n",
    "X_test = X_test.clone().detach().float()\n",
    "y_test = y_test.clone().detach().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device available: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA device available:\", torch.cuda.get_device_name(0))\n",
    "    # Enable cuDNN benchmark for faster training\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionWithContext(nn.Module):\n",
    "    def __init__(self, input_dim, bias=True):\n",
    "        super(AttentionWithContext, self).__init__()\n",
    "        self.W = nn.Parameter(torch.Tensor(input_dim, input_dim))\n",
    "        self.u = nn.Parameter(torch.Tensor(input_dim))\n",
    "        self.bias = bias\n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.Tensor(input_dim))\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.W)  # Initialize the weight matrix with Xavier uniform distribution\n",
    "        nn.init.uniform_(self.u, -0.1, 0.1)  # Initialize the attention vector with uniform distribution\n",
    "        if self.bias:\n",
    "            nn.init.zeros_(self.b)  # Initialize the bias with zeros\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Apply linear transformation\n",
    "        uit = torch.matmul(x, self.W)\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "        uit = torch.tanh(uit)\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        ait = torch.matmul(uit, self.u)\n",
    "        a = torch.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            a = a * mask.float()  # Apply mask\n",
    "\n",
    "        # Normalize attention weights\n",
    "        a = a / (torch.sum(a, dim=1, keepdim=True) + 1e-10)\n",
    "        a = a.unsqueeze(-1)\n",
    "        \n",
    "        # Compute weighted sum of inputs\n",
    "        weighted_input = x * a\n",
    "        return torch.sum(weighted_input, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=9):\n",
    "        super(ECGModel, self).__init__()\n",
    "        \n",
    "        # Define 5 convolutional layers, each with 12 filters\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 24, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(24, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 24, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(24, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 24, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(24, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 24, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(24, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 12, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Conv1d(12, 48, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Bidirectional GRU layer\n",
    "        self.gru = nn.GRU(input_size=48, hidden_size=12, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = AttentionWithContext(input_dim=24)\n",
    "        \n",
    "        # Batch normalization layer\n",
    "        self.batch_norm = nn.BatchNorm1d(24)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(24, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # [batch, channels, seq_len] for Conv1d\n",
    "        x = self.conv_layers(x)\n",
    "        # print(\"After Conv Layers:\", x.shape)  # Check shape\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # [batch, seq_len, channels] for GRU\n",
    "        x, _ = self.gru(x)\n",
    "        # print(\"After GRU Layer:\", x.shape)  # Check shape\n",
    "\n",
    "        x = self.attention(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = F.leaky_relu(x, 0.3)\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECGModel(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.3)\n",
       "    (2): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.3)\n",
       "    (4): Conv1d(12, 24, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.3)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): Conv1d(24, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (8): LeakyReLU(negative_slope=0.3)\n",
       "    (9): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (10): LeakyReLU(negative_slope=0.3)\n",
       "    (11): Conv1d(12, 24, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (12): LeakyReLU(negative_slope=0.3)\n",
       "    (13): Dropout(p=0.2, inplace=False)\n",
       "    (14): Conv1d(24, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (15): LeakyReLU(negative_slope=0.3)\n",
       "    (16): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (17): LeakyReLU(negative_slope=0.3)\n",
       "    (18): Conv1d(12, 24, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (19): LeakyReLU(negative_slope=0.3)\n",
       "    (20): Dropout(p=0.2, inplace=False)\n",
       "    (21): Conv1d(24, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (22): LeakyReLU(negative_slope=0.3)\n",
       "    (23): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (24): LeakyReLU(negative_slope=0.3)\n",
       "    (25): Conv1d(12, 24, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (26): LeakyReLU(negative_slope=0.3)\n",
       "    (27): Dropout(p=0.2, inplace=False)\n",
       "    (28): Conv1d(24, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (29): LeakyReLU(negative_slope=0.3)\n",
       "    (30): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (31): LeakyReLU(negative_slope=0.3)\n",
       "    (32): Conv1d(12, 48, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (33): LeakyReLU(negative_slope=0.3)\n",
       "    (34): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (gru): GRU(48, 12, batch_first=True, bidirectional=True)\n",
       "  (attention): AttentionWithContext()\n",
       "  (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=24, out_features=9, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = ECGModel(input_channels=12, num_classes=9)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss, suitable for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6999\n",
      "Epoch 2/100, Loss: 0.7020\n",
      "Epoch 3/100, Loss: 0.7003\n",
      "Epoch 4/100, Loss: 0.7002\n",
      "Epoch 5/100, Loss: 0.7012\n",
      "Epoch 6/100, Loss: 0.7013\n",
      "Epoch 7/100, Loss: 0.7004\n",
      "Epoch 8/100, Loss: 0.7014\n",
      "Epoch 9/100, Loss: 0.7012\n",
      "Epoch 10/100, Loss: 0.7002\n",
      "Epoch 11/100, Loss: 0.7020\n",
      "Epoch 12/100, Loss: 0.7001\n",
      "Epoch 13/100, Loss: 0.7010\n",
      "Epoch 14/100, Loss: 0.7005\n",
      "Epoch 15/100, Loss: 0.7013\n",
      "Epoch 16/100, Loss: 0.7015\n",
      "Epoch 17/100, Loss: 0.7017\n",
      "Epoch 18/100, Loss: 0.7004\n",
      "Epoch 19/100, Loss: 0.6995\n",
      "Epoch 20/100, Loss: 0.7006\n",
      "Epoch 21/100, Loss: 0.7010\n",
      "Epoch 22/100, Loss: 0.7002\n",
      "Epoch 23/100, Loss: 0.7017\n",
      "Epoch 24/100, Loss: 0.7013\n",
      "Epoch 25/100, Loss: 0.7007\n",
      "Epoch 26/100, Loss: 0.7001\n",
      "Epoch 27/100, Loss: 0.7004\n",
      "Epoch 28/100, Loss: 0.6993\n",
      "Epoch 29/100, Loss: 0.7005\n",
      "Epoch 30/100, Loss: 0.7003\n",
      "Epoch 31/100, Loss: 0.6997\n",
      "Epoch 32/100, Loss: 0.7008\n",
      "Epoch 33/100, Loss: 0.7006\n",
      "Epoch 34/100, Loss: 0.7004\n",
      "Epoch 35/100, Loss: 0.7021\n",
      "Epoch 36/100, Loss: 0.6998\n",
      "Epoch 37/100, Loss: 0.7013\n",
      "Epoch 38/100, Loss: 0.7008\n",
      "Epoch 39/100, Loss: 0.7002\n",
      "Epoch 40/100, Loss: 0.7010\n",
      "Epoch 41/100, Loss: 0.7011\n",
      "Epoch 42/100, Loss: 0.7016\n",
      "Epoch 43/100, Loss: 0.7006\n",
      "Epoch 44/100, Loss: 0.6996\n",
      "Epoch 45/100, Loss: 0.7010\n",
      "Epoch 46/100, Loss: 0.7000\n",
      "Epoch 47/100, Loss: 0.6999\n",
      "Epoch 48/100, Loss: 0.7017\n",
      "Epoch 49/100, Loss: 0.7007\n",
      "Epoch 50/100, Loss: 0.7004\n",
      "Epoch 51/100, Loss: 0.7005\n",
      "Epoch 52/100, Loss: 0.7007\n",
      "Epoch 53/100, Loss: 0.7015\n",
      "Epoch 54/100, Loss: 0.7006\n",
      "Epoch 55/100, Loss: 0.7011\n",
      "Epoch 56/100, Loss: 0.7002\n",
      "Epoch 57/100, Loss: 0.7012\n",
      "Epoch 58/100, Loss: 0.7003\n",
      "Epoch 59/100, Loss: 0.7010\n",
      "Epoch 60/100, Loss: 0.7004\n",
      "Epoch 61/100, Loss: 0.7018\n",
      "Epoch 62/100, Loss: 0.7004\n",
      "Epoch 63/100, Loss: 0.7005\n",
      "Epoch 64/100, Loss: 0.6995\n",
      "Epoch 65/100, Loss: 0.7011\n",
      "Epoch 66/100, Loss: 0.7000\n",
      "Epoch 67/100, Loss: 0.7001\n",
      "Epoch 68/100, Loss: 0.7018\n",
      "Epoch 69/100, Loss: 0.7012\n",
      "Epoch 70/100, Loss: 0.7004\n",
      "Epoch 71/100, Loss: 0.7006\n",
      "Epoch 72/100, Loss: 0.7012\n",
      "Epoch 73/100, Loss: 0.7001\n",
      "Epoch 74/100, Loss: 0.7003\n",
      "Epoch 75/100, Loss: 0.7000\n",
      "Epoch 76/100, Loss: 0.7004\n",
      "Epoch 77/100, Loss: 0.7002\n",
      "Epoch 78/100, Loss: 0.7008\n",
      "Epoch 79/100, Loss: 0.7010\n",
      "Epoch 80/100, Loss: 0.7004\n",
      "Epoch 81/100, Loss: 0.7003\n",
      "Epoch 82/100, Loss: 0.6999\n",
      "Epoch 83/100, Loss: 0.7012\n",
      "Epoch 84/100, Loss: 0.7010\n",
      "Epoch 85/100, Loss: 0.7008\n",
      "Epoch 86/100, Loss: 0.7010\n",
      "Epoch 87/100, Loss: 0.7006\n",
      "Epoch 88/100, Loss: 0.6997\n",
      "Epoch 89/100, Loss: 0.7006\n",
      "Epoch 90/100, Loss: 0.7013\n",
      "Epoch 91/100, Loss: 0.7002\n",
      "Epoch 92/100, Loss: 0.6993\n",
      "Epoch 93/100, Loss: 0.7016\n",
      "Epoch 94/100, Loss: 0.7017\n",
      "Epoch 95/100, Loss: 0.7003\n",
      "Epoch 96/100, Loss: 0.7013\n",
      "Epoch 97/100, Loss: 0.7004\n",
      "Epoch 98/100, Loss: 0.7001\n",
      "Epoch 99/100, Loss: 0.7006\n",
      "Epoch 100/100, Loss: 0.7009\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set training parameters\n",
    "epochs = 100  # Adjust the number of epochs as needed\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\", leave=False):\n",
    "    running_loss = 0.0  # Initialize cumulative loss\n",
    "    for inputs, labels in train_loader:\n",
    "        # Adjust the shape of the input data and convert to float type\n",
    "        inputs = inputs.permute(0, 2, 1).float()  # Adjust shape to [batch_size, channels, seq_len]\n",
    "        labels = labels.float()  # Convert labels to float type\n",
    "        # Move data to GPU (if supported)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass, compute loss, backward pass, and update weights\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Output average loss for each epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7125\n",
      "Test Accuracy: 11.50%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to record loss and accuracy\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Disable gradient calculation (evaluation mode does not require gradient computation)\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Adjust the shape of the input data and convert to float type\n",
    "        inputs = inputs.permute(0, 2, 1).float()  # Adjust shape to [batch_size, channels, seq_len]\n",
    "        labels = labels.float()  # Convert labels to float type\n",
    "        # Move data to GPU (if supported)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        \n",
    "        # Accumulate loss\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # For classification tasks, calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability\n",
    "        correct_predictions += (predicted == labels.argmax(dim=1)).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "# Output results\n",
    "print(f\"Test Loss: {average_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
